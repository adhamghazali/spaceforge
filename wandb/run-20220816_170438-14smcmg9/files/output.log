Epoch 1/8
--- Unet 1 ---
<torch.utils.data.dataloader.DataLoader object at 0x7f2d4da446d0>
Traceback (most recent call last):
  File "/home/azureuser/imagen/spaceforge/train.py", line 290, in <module>
    run_train_loop(cfg, trainer, loader, device, i=cfg["train"]["unet_number"])
  File "/home/azureuser/imagen/spaceforge/train.py", line 148, in run_train_loop
    train(cfg, dataloader, trainer, epoch, unet_num, device)
  File "/home/azureuser/imagen/spaceforge/train.py", line 88, in train
    loss = trainer(
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/imagen_pytorch/trainer.py", line 130, in inner
    out = fn(model, *args, **kwargs)
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/imagen_pytorch/trainer.py", line 919, in forward
    loss = self.imagen(*chunked_args, unet = self.unet_being_trained, unet_number = unet_number, **chunked_kwargs)
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/imagen_pytorch/imagen_pytorch.py", line 2380, in forward
    return self.p_losses(unet, images, times, text_embeds = text_embeds, text_mask = text_masks, cond_images = cond_images, noise_scheduler = noise_scheduler, lowres_cond_img = lowres_cond_img, lowres_aug_times = lowres_aug_times, pred_objective = pred_objective, p2_loss_weight_gamma = p2_loss_weight_gamma, random_crop_size = random_crop_size)
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/imagen_pytorch/imagen_pytorch.py", line 2280, in p_losses
    pred = unet.forward(
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/accelerate/utils/operations.py", line 507, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/torch/amp/autocast_mode.py", line 12, in decorate_autocast
    return func(*args, **kwargs)
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/imagen_pytorch/imagen_pytorch.py", line 1598, in forward
    x = attn_block(x, c)
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/imagen_pytorch/imagen_pytorch.py", line 964, in forward
    x = attn(x, context = context) + x
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/einops_exts/torch.py", line 17, in forward
    x = self.fn(x, **kwargs)
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/imagen_pytorch/imagen_pytorch.py", line 537, in forward
    attn = sim.softmax(dim = -1)
RuntimeError: CUDA out of memory. Tried to allocate 4.15 GiB (GPU 0; 79.17 GiB total capacity; 62.34 GiB already allocated; 2.62 GiB free; 69.13 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF