Epoch 1/8
--- Unet 1 ---
<torch.utils.data.dataloader.DataLoader object at 0x7fa7d214f6d0>
Train Step 1/40736 --- Loss: 0.6386
Traceback (most recent call last):
  File "/home/azureuser/imagen/spaceforge/train.py", line 290, in <module>
    run_train_loop(cfg, trainer, loader, device, i=cfg["train"]["unet_number"])
  File "/home/azureuser/imagen/spaceforge/train.py", line 148, in run_train_loop
    train(cfg, dataloader, trainer, epoch, unet_num, device)
  File "/home/azureuser/imagen/spaceforge/train.py", line 88, in train
    loss = trainer(
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/imagen_pytorch/trainer.py", line 130, in inner
    out = fn(model, *args, **kwargs)
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/imagen_pytorch/trainer.py", line 919, in forward
    loss = self.imagen(*chunked_args, unet = self.unet_being_trained, unet_number = unet_number, **chunked_kwargs)
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/imagen_pytorch/imagen_pytorch.py", line 2380, in forward
    return self.p_losses(unet, images, times, text_embeds = text_embeds, text_mask = text_masks, cond_images = cond_images, noise_scheduler = noise_scheduler, lowres_cond_img = lowres_cond_img, lowres_aug_times = lowres_aug_times, pred_objective = pred_objective, p2_loss_weight_gamma = p2_loss_weight_gamma, random_crop_size = random_crop_size)
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/imagen_pytorch/imagen_pytorch.py", line 2280, in p_losses
    pred = unet.forward(
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/accelerate/utils/operations.py", line 507, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/torch/amp/autocast_mode.py", line 12, in decorate_autocast
    return func(*args, **kwargs)
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/imagen_pytorch/imagen_pytorch.py", line 1621, in forward
    x = resnet_block(x, t)
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/imagen_pytorch/imagen_pytorch.py", line 697, in forward
    h = self.block1(x)
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/imagen_pytorch/imagen_pytorch.py", line 633, in forward
    x = self.groupnorm(x)
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 272, in forward
    return F.group_norm(
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/torch/nn/functional.py", line 2516, in group_norm
    return torch.group_norm(input, num_groups, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: CUDA out of memory. Tried to allocate 512.00 MiB (GPU 0; 79.17 GiB total capacity; 70.63 GiB already allocated; 287.56 MiB free; 71.41 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF