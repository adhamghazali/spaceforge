Epoch 1/8
--- Unet 1 ---
<torch.utils.data.dataloader.DataLoader object at 0x7f4f96666a00>







































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































Train Step 1000/40736 --- Loss: 0.0206 unet 2 has not been trained
unet 3 has not been trained
when sampling, you can pass stop_at_unet_number to stop early in the cascade, so it does not try to generate with untrained unets
0it [00:00, ?it/s]




















































































0it [02:50, ?it/s] step: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [02:46<00:00,  4.23it/s]
checkpoint saved to /datadrive4T/checkpoint/imagen_large_checkpoint.pt
Train Step 1001/40736 --- Loss: 0.0203
Traceback (most recent call last):
  File "/home/azureuser/imagen/spaceforge/train.py", line 290, in <module>
    run_train_loop(cfg, trainer, loader, device, i=cfg["train"]["unet_number"])
  File "/home/azureuser/imagen/spaceforge/train.py", line 148, in run_train_loop
    train(cfg, dataloader, trainer, epoch, unet_num, device)
  File "/home/azureuser/imagen/spaceforge/train.py", line 88, in train
    loss = trainer(
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/imagen_pytorch/trainer.py", line 130, in inner
    out = fn(model, *args, **kwargs)
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/imagen_pytorch/trainer.py", line 919, in forward
    loss = self.imagen(*chunked_args, unet = self.unet_being_trained, unet_number = unet_number, **chunked_kwargs)
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/imagen_pytorch/imagen_pytorch.py", line 2380, in forward
    return self.p_losses(unet, images, times, text_embeds = text_embeds, text_mask = text_masks, cond_images = cond_images, noise_scheduler = noise_scheduler, lowres_cond_img = lowres_cond_img, lowres_aug_times = lowres_aug_times, pred_objective = pred_objective, p2_loss_weight_gamma = p2_loss_weight_gamma, random_crop_size = random_crop_size)
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/imagen_pytorch/imagen_pytorch.py", line 2280, in p_losses
    pred = unet.forward(
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/accelerate/utils/operations.py", line 507, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/torch/amp/autocast_mode.py", line 12, in decorate_autocast
    return func(*args, **kwargs)
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/imagen_pytorch/imagen_pytorch.py", line 1621, in forward
    x = resnet_block(x, t)
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/imagen_pytorch/imagen_pytorch.py", line 703, in forward
    h = self.block2(h, scale_shift = scale_shift)
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/azureuser/miniconda3/envs/imagen/lib/python3.9/site-packages/imagen_pytorch/imagen_pytorch.py", line 637, in forward
    x = x * (scale + 1) + shift
RuntimeError: CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 79.17 GiB total capacity; 66.46 GiB already allocated; 22.56 MiB free; 66.97 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF