dataset:
  dataset_name: "cc12m"
  dataset_path: "/datadrive4T/cc12m_w_embeds/{00000..01242}.tar"
  image_size: 256
  shuffle_size: 100000
  shuffle_initial: 2500
  shard_shuffle: True
  num_images: 10428650 
  num_workers: 12
  prefetch_factor: 1
  pin_memory: True
  drop_last: True
  precomputed_embeddings: True
train:
  epochs: 8
  batch_size: 256
  unet_number: 1 # dummy stuff unets are passed in code!
  unet1_max_batch_size: 16
  unet2_max_batch_size: 4
  load_checkpoint: False
  load_checkpoint_path:  "/datadrive4T/checkpoint/imagen_large_checkpoint.pt"
  checkpoint_rate: 1000
  checkpoint_path:  "/datadrive4T/checkpoint/imagen_large_checkpoint.pt"
  checkpoint_strict: True
  checkpoint_model_only: False
  image_non_blocking: True
  embedding_non_blocking: False
  cudnn_benchmark: True
  use_ema: True
  lr: 0.000015
  eps: 0.00000001
  beta1: 0.9
  beta2: 0.99
  max_grad_norm: None
  amp: True
  group_wd_params: True
  warmup_steps: None
  cosine_decay_max_steps: None
  cond_scale: 7.5
  sample_texts: ['a 3d render of a purple cow, highly detailed','a sports car sketch']
model:
  text_encoder_name: "google/t5-v1_1-xl"
  image_sizes: [64, 256, 1024]
  cond_drop_prob: 0.1
  timesteps: 1000
  unet1:
    dim: 256 #paper-config is 512
    cond_dim: 512
    dim_mults: [1, 2, 3, 4]
    num_resnet_blocks: 3
    layer_attns: [False, True, True, True]
    layer_cross_attns: [False, True, True, True]
    attn_heads: 8
    ff_mult: 2
    dropout: 0.1
    memory_efficient: False
    cosine_sim_attn: False
    use_linear_attn: False
  unet2:
    dim: 128
    cond_dim: 512
    dim_mults: [1, 2, 4, 8]
    num_resnet_blocks: [2, 4, 8, 8]
    layer_attns: [False, False, False, True]
    layer_cross_attns: [False, False, False, True]
    attn_heads: 8
    ff_mult: 2
    dropout: 0.1
    memory_efficient: True
    cosine_sim_attn: False
    use_linear_attn: False
  unet3:
    dim: 128
    cond_dim: 512
    dim_mults: [1, 2, 4, 8]
    num_resnet_blocks: [2, 4, 8, 8]
    layer_attns: [False, False, False, True]
    layer_cross_attns: [False, False, False, True]
    attn_heads: 8
    ff_mult: 2
    dropout: 0.1
    memory_efficient: True
    cosine_sim_attn: False
    use_linear_attn: False
